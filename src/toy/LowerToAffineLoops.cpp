#include "mlir/Dialect/Affine/IR/AffineOps.h"
#include "mlir/Dialect/Arith/IR/Arith.h"
#include "mlir/Dialect/Func/IR/FuncOps.h"
#include "mlir/Dialect/MemRef/IR/MemRef.h"
#include "mlir/IR/BuiltinAttributes.h"
#include "mlir/IR/BuiltinDialect.h"
#include "mlir/IR/BuiltinOps.h"
#include "mlir/IR/BuiltinTypes.h"
#include "mlir/IR/Diagnostics.h"
#include "mlir/IR/DialectRegistry.h"
#include "mlir/IR/MLIRContext.h"
#include "mlir/IR/Operation.h"
#include "mlir/IR/PatternMatch.h"
#include "mlir/IR/ValueRange.h"
#include "mlir/Pass/Pass.h"
#include "mlir/Support/LLVM.h"
#include "mlir/Support/TypeID.h"
#include "mlir/Transforms/DialectConversion.h"

#include "Passes.h"
#include "toy/Dialect.h"

#include "llvm/ADT/ArrayRef.h"
#include "llvm/ADT/STLExtras.h"
#include "llvm/ADT/Sequence.h"
#include "llvm/Support/Casting.h"
#include "llvm/Support/LogicalResult.h"

#include <cstdint>
#include <memory>
#include <utility>

using namespace ::mlir;

/// Convert the given tensor type to MemRefType.
static MemRefType convertTensorToMemRef(RankedTensorType tensorType) {
    return MemRefType::get(tensorType.getShape(), tensorType.getElementType());
}

/// Insert memery alloc and dealloc opeartion for the given MemRefType.
static Value
insertAllocAndDealloc(MemRefType type, Location loc, PatternRewriter& rewriter) {
    auto  alloc = rewriter.create<memref::AllocaOp>(loc, type);
    auto* parentBlock = alloc->getBlock();
    alloc->moveAfter(&parentBlock->front());

    auto dealloc = rewriter.create<memref::DeallocOp>(loc, alloc);
    dealloc->moveBefore(&parentBlock->back());

    return alloc;
}


/// loopIvs is a vector describes the index of the tensor element to be lowered.
/// Such as loopIvs = [1, 2, 3] means tensor[1][2][3].
using LoopIteratorFn = llvm::function_ref<
    Value(OpBuilder& rewriter, ValueRange memRefOperands, ValueRange loopIvs)>;


/**
 * @function: lower the Operation "op" to affine operation.
 * @argument: op:               The toy operation to be lowered.
 *            operands:         Store the Value of tensor.
 *            rewriter:         rewriter builder.
 *            processIteration: A function to build a tensor element value;
 */
static void lowerOpToLoops(
    Operation*       op,
    ValueRange       operands,
    PatternRewriter& rewriter,
    LoopIteratorFn   processIteration) {
    // get the result type, Op do not have OneResult OpTrait so Op.getResult is vaild.
    auto resultTensorType = llvm::cast<RankedTensorType>(*op->result_type_begin());
    auto loc = op->getLoc();

    // affine result tensor to memref.
    auto resultMemRefType = convertTensorToMemRef(resultTensorType);
    auto alloc = insertAllocAndDealloc(resultMemRefType, loc, rewriter);

    llvm::SmallVector<int64_t, 4> lowerBounds(resultTensorType.getRank(), 0);
    llvm::SmallVector<int64_t, 4> steps(resultTensorType.getRank(), 1);

    // lbs, ubs, steps: lowerBounds, upperBounds ans steps for loops.
    // callback function will be called in each loops.
    affine::buildAffineLoopNest(
        rewriter, loc, lowerBounds, resultTensorType.getShape(), steps,
        [&](OpBuilder& builder, Location loc, ValueRange loopIvs) {
            auto valueToStore = processIteration(builder, operands, loopIvs);
            builder.create<affine::AffineStoreOp>(loc, valueToStore, alloc, loopIvs);
        });

    rewriter.replaceOp(op, alloc);
};


// =========================================
//       Lowering Pattern Rewriter
// =========================================

namespace {
// ConversionPattern to lowering toy.transposeOp.
struct TransposeOpLowering : public ConversionPattern {
public:
    TransposeOpLowering(MLIRContext* ctx)
        : ConversionPattern(toy::TransposeOp::getOperationName(), 1, ctx) {}

    virtual llvm::LogicalResult matchAndRewrite(
        Operation*                 op,
        ArrayRef<Value>            operands,
        ConversionPatternRewriter& rewriter) const override {
        auto loc = op->getLoc();

        lowerOpToLoops(
            op, operands, rewriter,
            [loc](OpBuilder& builder, ValueRange memRefOperands, ValueRange loopIvs) {
                // Generate an adaptor for the remapped operands of the
                // TransposeOp. This allows for using the nice named
                // accessors that are generated by the ODS.
                toy::TransposeOpAdaptor transposeAdaptor(memRefOperands);
                Value                   input = transposeAdaptor.getInput();

                // Transpose the elements by generating a load from the
                // reverse indices.
                SmallVector<Value, 2> reverseIvs(llvm::reverse(loopIvs));
                return builder.create<affine::AffineLoadOp>(loc, input, reverseIvs);
            });

        return llvm::success();
    }
};

template <typename BinaryOp, typename LoweredBinaryOp>
struct BinaryOpLowering : ConversionPattern {
    BinaryOpLowering(MLIRContext* ctx)
        : ConversionPattern(BinaryOp::getOperationName(), 1, ctx) {}

    LogicalResult matchAndRewrite(
        Operation*                 op,
        ArrayRef<Value>            operands,
        ConversionPatternRewriter& rewriter) const override {
        auto loc = op->getLoc();

        lowerOpToLoops(
            op, operands, rewriter,
            [loc](OpBuilder& rewriter, ValueRange memRefOperands, ValueRange loopIvs) {
                typename BinaryOp::Adaptor binaryAdaptor(memRefOperands);

                auto loadLhs = rewriter.create<affine::AffineLoadOp>(
                    loc, binaryAdaptor.getLhs(), loopIvs);
                auto loadRhs = rewriter.create<affine::AffineLoadOp>(
                    loc, binaryAdaptor.getRhs(), loopIvs);

                return rewriter.create<LoweredBinaryOp>(loc, loadLhs, loadRhs);
            });

        return success();
    }
};
using AddOpLowering = BinaryOpLowering<toy::AddOp, arith::AddFOp>;
using MulOpLowering = BinaryOpLowering<toy::MulOp, arith::MulFOp>;


// Lowering toy.ConstantOp to AffineDialect.
struct ConstantOpLowering : public OpRewritePattern<toy::ConstantOp> {
    using OpRewritePattern<toy::ConstantOp>::OpRewritePattern;

    llvm::LogicalResult
    matchAndRewrite(toy::ConstantOp op, PatternRewriter& rewriter) const override {
        DenseElementsAttr constantValue = op.getValue();
        // ConstantOp has a attribute argument named value, So tblgen a getValue method.
        auto loc = op->getLoc();

        // Get memref Type and insert alloc operation.
        auto tensorType = llvm::cast<RankedTensorType>(op.getType());
        auto memrefType = convertTensorToMemRef(tensorType);
        auto alloc = insertAllocAndDealloc(memrefType, loc, rewriter);

        auto                  valueShape = memrefType.getShape();
        SmallVector<Value, 8> constantIndices;

        if (!valueShape.empty()) {
            for (auto i : llvm::seq<int64_t>(0, *llvm::max_element(valueShape))) {
                constantIndices.push_back(
                    rewriter.create<arith::ConstantIndexOp>(loc, i));
            }
        }
        else {
            constantIndices.push_back(rewriter.create<arith::ConstantIndexOp>(loc, 0));
        }


        // store tensor value to memref.
        SmallVector<Value, 2>        indices;  // indices for element value in loops.
        auto                         valueIt = constantValue.value_begin<FloatAttr>();
        function_ref<void(uint64_t)> storeElements = [&](uint64_t dimension) {
            if (dimension == valueShape.size()) {
                auto valueToStore = rewriter.create<arith::ConstantOp>(loc, *valueIt++);
                rewriter.create<affine::AffineStoreOp>(
                    loc, valueToStore, alloc, llvm::ArrayRef(indices));
                return;
            }

            for (uint64_t i = 0, e = valueShape[dimension]; i != e; i++) {
                indices.push_back(constantIndices[i]);
                storeElements(dimension + 1);
                indices.pop_back();
            }
        };

        storeElements(/*dimension:*/ 0);

        rewriter.replaceOp(op, alloc);
        return success();
    }
};


// We do not want to lowering toy.PrintOp to affine. But we have to change toy.PrintOp's
// Operand from tensorType to memref.
class PrintOpLowering : public OpConversionPattern<toy::PrintOp> {
    using OpConversionPattern<toy::PrintOp>::OpConversionPattern;

    virtual LogicalResult matchAndRewrite(
        toy::PrintOp               op,
        toy::PrintOp::Adaptor      adaptor,
        ConversionPatternRewriter& rewriter) const override {
        rewriter.modifyOpInPlace(op, [&]() { op->setOperands(adaptor.getOperands()); });
        return success();
    }
};


class FuncOpLowering : public OpConversionPattern<toy::FuncOp> {
    using OpConversionPattern<toy::FuncOp>::OpConversionPattern;

    virtual LogicalResult matchAndRewrite(
        toy::FuncOp                op,
        OpAdaptor                  adaptor,
        ConversionPatternRewriter& rewriter) const override {
        // only lowering main function.
        if (op.getName() != "main") {
            return failure();
        }

        // main function is supposed to have no argument and result.
        if (op.getNumArguments() || op.getFunctionType().getNumResults()) {
            return rewriter.notifyMatchFailure(op, [](Diagnostic& diag) {
                diag << "expected 'main' to have 0 inputs and 0 results";
            });
        }

        auto loc = op->getLoc();
        auto func =
            rewriter.create<func::FuncOp>(loc, op.getName(), op.getFunctionType());
        rewriter.inlineRegionBefore(op.getRegion(), func->getRegion(0), func.end());
        rewriter.eraseOp(op);

        return success();
    }
};


class ReturnOpLowering : public OpConversionPattern<toy::ReturnOp> {
    using OpConversionPattern<toy::ReturnOp>::OpConversionPattern;

    LogicalResult matchAndRewrite(
        toy::ReturnOp              op,
        OpAdaptor                  adaptor,
        ConversionPatternRewriter& rewriter) const override {
        if (op.hasOperand())
            return failure();

        rewriter.replaceOpWithNewOp<func::ReturnOp>(op);
        return success();
    }
};
}  // namespace


// =========================================
//        ToyToAffineLoweringPass
// =========================================
namespace {
struct ToyToAffineLoweringPass
    : public PassWrapper<ToyToAffineLoweringPass, OperationPass<ModuleOp>> {
    MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(ToyToAffineLoweringPass)

    void getDependentDialects(DialectRegistry& registry) const override {
        registry.insert<affine::AffineDialect, func::FuncDialect, memref::MemRefDialect>();
    }
    void runOnOperation() final;
};  // struct ToyToAffineLoweringPass
}  // namespace

void ToyToAffineLoweringPass::runOnOperation() {
    ConversionTarget target(getContext());

    target.addLegalDialect<
        affine::AffineDialect, BuiltinDialect, arith::ArithDialect, func::FuncDialect,
        memref::MemRefDialect>();

    target.addIllegalDialect<toy::ToyDialect>();
    target.addDynamicallyLegalOp<toy::PrintOp>([](toy::PrintOp op) {
        return llvm::none_of(
            op->getOperandTypes(), [](Type type) { return llvm::isa<TensorType>(type); });
    });

    RewritePatternSet patterns(&getContext());
    patterns.add<
        ConstantOpLowering, TransposeOpLowering, PrintOpLowering, FuncOpLowering,
        ReturnOpLowering, AddOpLowering, MulOpLowering>(&getContext());

    if (llvm::failed(applyPartialConversion(getOperation(), target, std::move(patterns))))
        signalPassFailure();
}


// Add a function to get ToyToAffineLoweringPass ptr.
std::unique_ptr<Pass> mlir::toy::createLowerToAffinePass() {
    return std::make_unique<ToyToAffineLoweringPass>();
}
